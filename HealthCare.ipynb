{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importacion de Biblioteca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí importaremos todas las bibliotecas necesarias para el análisis de sentimientos y la clasificación de comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de recursos de NLTK\n",
    "\n",
    " Descargaremos los recursos necesarios de NLTK, como stopwords y el lexicon para análisis de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\juand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\juand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\juand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\juand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización de Reddit y Obtención de comentarios\n",
    "\n",
    "Aquí inicializaremos la API de Reddit utilizando la biblioteca PRAW. Ademas, recopilaremos comentarios de Reddit de un subreddit sobre los seguros de Salud en USA con un liminte de 20 posts y los almacenaremos en una lista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id='vkbyNxlrdz1Wy9DNxfxnzA',\n",
    "    client_secret='sC4RfUNF95ThEF0BtuTyfD1sV6DyWA',\n",
    "    user_agent='my-app by u/Witty-Cause-3665'\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit('Health')\n",
    "posts = subreddit.search(\" Healthcare USA\", limit=20\n",
    "                        )\n",
    "comments_data = []\n",
    "\n",
    "for post in posts:\n",
    "    post.comments.replace_more(limit=None)\n",
    "    for comment in post.comments.list():\n",
    "        comments_data.append(comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de texto y Análisis de sentimientos\n",
    "Limpiaremos y procesaremos los comentarios antes de realizar el análisis de sentimientos. Por ultimo, Usaremos el SentimentIntensityAnalyzer de NLTK para realizar el análisis de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    return sentiment_score['compound']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de sentimientos\n",
    "\n",
    "\n",
    "Utilizaremos el SentimentIntensityAnalyzer de NLTK para llevar a cabo el análisis de sentimientos. Posteriormente, aplicaremos el preprocesamiento y el análisis de sentimientos a los comentarios recopilados. Después, procederemos a crear un DataFrame de pandas para almacenar los comentarios procesados y sus etiquetas de sentimiento. Seguidamente, dividiremos los datos en conjuntos de entrenamiento y prueba. Luego, emplearemos TF-IDF para convertir los comentarios en características numéricas. Acto seguido, entrenaremos un modelo SVM para la clasificación de sentimientos. Una vez completado el entrenamiento, realizaremos predicciones en el conjunto de prueba y evaluaremos el rendimiento del modelo. Finalmente, crearemos un DataFrame para mostrar los comentarios, tanto el sentimiento real como el sentimiento predicho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment Body</th>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>In fairness, several of the countries that spe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Do these new case reports ever take into accou...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It’s ironic. Independence Day 2020 could turn ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>So, \"not for profit\" doesn't mean no one is ma...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>What are you implying</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Then you don’t have any issue with Trump havin...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>So this is going to be another one of his futu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>If it wasn't for profit, why would anyone inve...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Perhaps a trip overseas ?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>My guess it that Saddam was set up.  We've wan...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Comment Body Actual Sentiment  \\\n",
       "327  In fairness, several of the countries that spe...         Positive   \n",
       "33   Do these new case reports ever take into accou...          Neutral   \n",
       "15   It’s ironic. Independence Day 2020 could turn ...         Positive   \n",
       "314  So, \"not for profit\" doesn't mean no one is ma...         Positive   \n",
       "57                               What are you implying          Neutral   \n",
       "..                                                 ...              ...   \n",
       "94   Then you don’t have any issue with Trump havin...         Positive   \n",
       "195  So this is going to be another one of his futu...         Positive   \n",
       "311  If it wasn't for profit, why would anyone inve...         Negative   \n",
       "292                          Perhaps a trip overseas ?          Neutral   \n",
       "347  My guess it that Saddam was set up.  We've wan...          Neutral   \n",
       "\n",
       "    Predicted Sentiment  \n",
       "327            Positive  \n",
       "33             Positive  \n",
       "15             Positive  \n",
       "314            Positive  \n",
       "57              Neutral  \n",
       "..                  ...  \n",
       "94             Negative  \n",
       "195            Positive  \n",
       "311            Negative  \n",
       "292            Positive  \n",
       "347            Negative  \n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    return sentiment_score['compound']\n",
    "comments_processed = [preprocess_text(comment) for comment in comments_data]\n",
    "sentiments = [analyze_sentiment(comment) for comment in comments_processed]\n",
    "sentiment_labels = ['Positive' if score > 0.05 else 'Negative' if score < -0.05 else 'Neutral' for score in sentiments]\n",
    "\n",
    "data = pd.DataFrame({'Comment Body': comments_data, 'Sentiment': sentiment_labels})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Comment Body'], data['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "results_df_HealthCare = pd.DataFrame({'Comment Body': X_test, 'Actual Sentiment': y_test, 'Predicted Sentiment': y_pred})\n",
    "\n",
    "results_df_HealthCare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_HealthCare.to_csv('results_df_HealthCare.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
